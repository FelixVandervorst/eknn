{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c0b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import multivariate_normal, normal\n",
    "import faiss, sklearn\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850f1a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44be1f592053422e9cadbede72af4a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2750b7094c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_cycle = 100\n",
    "theta1 = np.linspace(np.pi, 2*np.pi + np.pi, lenght_cycle)\n",
    "theta2 = np.linspace(0, 2*np.pi, lenght_cycle)\n",
    "radius = 5\n",
    "X=np.zeros((lenght_cycle*2,2))\n",
    "my=np.zeros((lenght_cycle*2,3))\n",
    "y=np.zeros((lenght_cycle*2,2))\n",
    "t=np.zeros((lenght_cycle*2))\n",
    "for i in range(lenght_cycle):\n",
    "    mean1 = [radius*np.cos(theta1[i]), radius*np.sin(theta1[i])]\n",
    "    mean2 = [radius*np.cos(theta2[i]), radius*np.sin(theta2[i])]\n",
    "    cov = [[1, 0], [0, 1]]\n",
    "    X[2 * i+1, :] = multivariate_normal(mean1, cov, size=1)\n",
    "    X[(2 * i), :] = multivariate_normal(mean2, cov, size=1)\n",
    "    my[2 * i+1, 0] = 1 - min(0.5, normal(0, 0.3, size=1)[0] ** 2) # a little bit of uncertainty\n",
    "    my[(2 * i), 1] = 1 - min(0.5, normal(0, 0.3, size=1)[0] ** 2) # a little bit of uncertainty\n",
    "    y[2 * i+1, 0] = 1  # a little bit of uncertainty\n",
    "    y[(2 * i), 1] = 1\n",
    "    t[2 * i+1] = i\n",
    "    t[(2 * i)] = i\n",
    "\n",
    "my[:,2] = 1 - my[:,0] - my[:,1] # the 'masses' in training set\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d8c86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad8eb78340640d7ae2195efc81a672e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X[:,0], X[:,1], t, c=y[:,0])\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5606d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "n = X.shape[0]\n",
    "D = np.zeros((n,k))\n",
    "I = np.zeros((n,k))\n",
    "index = faiss.IndexFlatL2(X.shape[1])\n",
    "index.add(np.ascontiguousarray(X[:k, :],\n",
    "                               dtype=np.float32))  # should convert once to arrays np.float out of loop.\n",
    "for i in range(k, n):\n",
    "    D[i, :], I[i, :] = index.search(np.ascontiguousarray(X[i, :].reshape(1, 2), dtype=np.float32), k=5)\n",
    "    index.add(np.ascontiguousarray(X[i,:].reshape(1,2), dtype=np.float32))  # should convert once to arrays np.float out of loop.\n",
    "\n",
    "I = I.astype(int)\n",
    "T = (np.expand_dims(t, axis=1) - t[I])/max(t) # relative time difference of neighbor j to observation i\n",
    "\n",
    "pl = my[:,:2] + np.expand_dims(my[:,2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "211dcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient(decays, I, D, pl, T):\n",
    "    dists = D ** 2\n",
    "    times = T ** 2\n",
    "    k = I.shape[1]\n",
    "    alpha = 1 / (1 + np.exp(decays[0]))\n",
    "    gamma = decays[1:3] ** 2\n",
    "    tau = decays[3:5] ** 2\n",
    "    beta = alpha * (np.exp(-gamma.reshape(1, 1, 2) * dists.reshape(dists.shape[0], dists.shape[1], 1))) * np.exp(-tau.reshape(1, 1, 2) * times.reshape(dists.shape[0], dists.shape[1], 1))\n",
    "    discounted_pl = 1 - beta + (beta * pl[I])\n",
    "    hat_pl = discounted_pl[:, 0, :]\n",
    "    for n in range(1, k - 1):\n",
    "        hat_pl = hat_pl * discounted_pl[:, n, :]\n",
    "    norm_hat_pl = hat_pl / (hat_pl.sum(axis=1).reshape(hat_pl.shape[0], 1))\n",
    "    # gradient calculation cf Algorithm 3 Denoeux et al. 2019\n",
    "    a4 = pl / np.expand_dims((norm_hat_pl * pl).sum(axis=1), axis=1)  # A.4 (i,q)\n",
    "    a8 = (np.expand_dims(-hat_pl, axis=1) * (1 - pl[I])) / (\n",
    "            1 - (beta * (1 - pl[I])))  # A.8 (i,K,q) !!! not ok check denominator\n",
    "    a9 = - beta * np.expand_dims(dists, axis=2)  # A.9 (i,K,q)\n",
    "    a9t = - beta * np.expand_dims(times, axis=2)\n",
    "    a13 = beta / alpha  # A.13 (i,K,q)\n",
    "    a7 = (a8 * a9).sum(axis=1)  # A.7 (i,q)\n",
    "    a7t = (a8 * a9t).sum(axis=1)\n",
    "    a12 = (a8 * a13).sum(axis=1)  # A.12 (i,q)\n",
    "    a6_1 = (1 - norm_hat_pl) / (hat_pl.sum(axis=1).reshape(hat_pl.shape[0], 1))  # (i,q=0,k=0) & (i,q=1,k=1)\n",
    "    a6_2 = -hat_pl / (hat_pl.sum(axis=1).reshape(hat_pl.shape[0], 1) ** 2)  # (i,q=0,k=1) & (i,q=1,k=0)\n",
    "    a6 = np.stack((np.stack((a6_1[:, 0], a6_2[:, 0]), axis=1),\n",
    "                   np.stack((a6_2[:, 1], a6_1[:, 1]), axis=1)),\n",
    "                  axis=2)  # (i,k,q)\n",
    "    a5 = a6 * np.expand_dims(a7, axis=2)  # (i,k,q)\n",
    "    a5t = a6 * np.expand_dims(a7t, axis=2)\n",
    "    a3 = 2 * np.expand_dims(decays[1:3], axis=0) * (np.expand_dims(a4, axis=1) * a5).sum(\n",
    "        axis=2)  # (i,k)\n",
    "    a3t = 2 * np.expand_dims(decays[3:5], axis=0) * (np.expand_dims(a4, axis=1) * a5t).sum(\n",
    "        axis=2)  # (i,k)\n",
    "    a11 = (a6 * np.expand_dims(a12, axis=2)).sum(axis=1)\n",
    "    a10 = -alpha * (1 - alpha) * (a4 * a11).sum(axis=1)\n",
    "    a1 = a3.sum(axis=0)\n",
    "    a1t = a3t.sum(axis=0)\n",
    "    a2 = a10.sum(axis=0)\n",
    "    return -np.concatenate((np.array([a2]),a1, a1t))\n",
    "def eloglik(decays, I, D , pl, T):\n",
    "    dists = D ** 2\n",
    "    times = T ** 2 # if missing just set to 0 and we have back the original algo\n",
    "    k = I.shape[1]\n",
    "    alpha = 1 / (1 + np.exp(decays[0]))\n",
    "    gamma = decays[1:3] ** 2\n",
    "    tau = decays[3:5] ** 2\n",
    "    beta = alpha * (np.exp(-gamma.reshape(1, 1, 2) * dists.reshape(dists.shape[0], dists.shape[1], 1))) * np.exp(\n",
    "        -tau.reshape(1, 1, 2) * times.reshape(dists.shape[0], dists.shape[1], 1))\n",
    "    discounted_pl = 1 - beta + (beta * pl[I])\n",
    "    hat_pl = discounted_pl[:, 0, :]\n",
    "    for n in range(1, k - 1):\n",
    "        hat_pl = hat_pl * discounted_pl[:, n, :]\n",
    "    norm_hat_pl = hat_pl / (hat_pl.sum(axis=1).reshape(hat_pl.shape[0], 1))\n",
    "    #print('difference' + str((abs(norm_hat_pl - pl)).sum()))\n",
    "    return -np.sum(np.log((norm_hat_pl * pl).sum(axis=1)))\n",
    "#decays = np.array([-5 , 0.1, 0.1, 0 , 0.1])\n",
    "\n",
    "def predict_eknn(decays, I, D, my, T):\n",
    "    nb = I\n",
    "    dists = D ** 2 #preds[0]\n",
    "    times = T ** 2\n",
    "    k = nb.shape[1]\n",
    "    alpha = 1 / (1 + np.exp(decays[0]))\n",
    "    gamma = decays[1:3] ** 2\n",
    "    tau = decays[3:5] ** 2\n",
    "    m0 = my[nb][:,:,0] * alpha * (np.exp(-gamma[0] * dists)) * (np.exp(-tau[0] * times))\n",
    "    m1 = my[nb][:,:,1] * alpha * (np.exp(-gamma[1] * dists)) * (np.exp(-tau[1] * times))\n",
    "    m10 = 1 - m0 - m1\n",
    "    m0t = m0[:,0]\n",
    "    m1t = m1[:,0]\n",
    "    m10t = m10[:,0]\n",
    "    for n in range(k-1):\n",
    "        denominators = 1 - (m0t * m1[:,n+1] + m0[:,n+1] * m1t) # denominators\n",
    "        m0t = (m0t * m10[:,n+1] + m0[:,n+1] * m10t + m0t * m0[:,n+1])/denominators\n",
    "        m1t = (m1t * m10[:,n+1] + m1[:,n+1] * m10t + m1t * m1[:,n+1])/denominators\n",
    "        m10t = 1 - m0t - m1t\n",
    "    return np.vstack((m0t,m1t,m10t)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cdf1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 30.616535\n",
      "         Iterations: 15\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 76\n",
      "Obtained parameter values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-7.01822609e+00,  5.63741433e-03,  1.70191304e-03,  4.73033886e+00,\n",
       "        5.07068088e+00])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = minimize(eloglik, np.array((0, 0.5, 0.5, 2,  2)), method='BFGS', jac=Gradient,\n",
    "               options={'gtol': 1e-6,'disp': True}, args=(I, D, pl, T)) # or BFGS or 'Nelder-Mead'\n",
    "print('Obtained parameter values: ')\n",
    "res.x #to check and interpret results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be27909c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022f78a6a3be4dfcb6236009f50747fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Evidential Knn for $m(\\\\mathscr{E} = , -7.0,\\\\eta_0 = 0.0, \\\\eta_1 = 0.0,\\\\tau_0 = 4.7,\\\\tau_1 = 5.1)$ at time 100 (end of animation)')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_eknn_new(X_test = [4, 4], index=index, resx = res.x, my = my, t = t):\n",
    "    D, I = index.search(np.ascontiguousarray(X_test, dtype=np.float32).reshape(1,2), k=5) # the full history is there if we do it like this\n",
    "    T = (max(t) - t[I])/max(t) # relative time difference of neighbor j to observation i\n",
    "    result = predict_eknn(resx, I=I, D=D, my=my, T=T)\n",
    "    return(result)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "h = .05\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "grid_to_assess = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "Z = np.apply_along_axis(predict_eknn_new, 1, grid_to_assess)\n",
    "\n",
    "m1 = Z[:,0, 0].ravel().reshape(xx.shape)\n",
    "m2 = Z[:,0, 1].ravel().reshape(xx.shape)\n",
    "m3 = Z[:,0, 2].ravel().reshape(xx.shape)\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3, subplot_kw={\"projection\": \"3d\"})\n",
    "ax1.set_title(r'$m(\\theta_0)$')\n",
    "ax1.plot_surface(xx, yy, m1,cmap=cm.coolwarm,linewidth=0, antialiased=False,alpha=.5, label = 'mass')\n",
    "ax1.scatter(X[:,0], X[:,1],c=(my[:,0]+my[:,2]/2), label='training points')\n",
    "ax2.set_title(r'$m(\\theta_1)$')\n",
    "ax2.plot_surface(xx, yy, m2,cmap=cm.coolwarm,linewidth=0, antialiased=False,alpha=.5, label = 'mass')\n",
    "ax2.scatter(X[:,0], X[:,1],c=(my[:,0]+my[:,2]/2), label='training points')\n",
    "ax3.set_title(r'$m(\\Theta)$ Uncertainy')\n",
    "ax3.plot_surface(xx, yy, m3,cmap=cm.coolwarm,linewidth=0, antialiased=False,alpha=.5, label = 'mass')\n",
    "ax3.scatter(X[:,0], X[:,1],c=(my[:,0]+my[:,2]/2), label='training points')\n",
    "fig.suptitle(r'Evidential Knn for $m(\\mathscr{E} = , ' + str(round(res.x[0])) +\n",
    "             r',\\eta_0 = ' +str(round(res.x[1],  1)) +\n",
    "             r', \\eta_1 = ' +str(round(res.x[2], 1)) +\n",
    "             r',\\tau_0 = ' + str(round(res.x[3], 1)) +\n",
    "             r',\\tau_1 = ' + str(round(res.x[4], 1)) +\n",
    "             r')$ at time 100 (end of animation)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73a2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
